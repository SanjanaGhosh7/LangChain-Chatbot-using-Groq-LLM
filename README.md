# LangChain-Chatbot-using-Groq-LLM
ğŸ§¬ LangChain Chatbot using Groq LLM

This project is a simple AI chatbot built using LangChain and Groqâ€™s Llama 3.3 70B model.
It demonstrates how to integrate an LLM into a conversational app using prompt templates, parsing, and environment management.

ğŸš€ Project Overview

The chatbot:

Accepts user input in a conversational loop.

Uses ChatPromptTemplate from LangChain to dynamically construct prompts.

Connects to Groqâ€™s Llama 3.3-70B model for generating intelligent, context-aware responses.

Uses StrOutputParser to parse the output into readable text.

Supports chat history â€” maintaining context between turns.

Runs fully in your terminal.

ğŸ§° Tech Stack   
Component           	       Purpose
Python                      Core programming language
LangChain	                  Framework for building LLM workflows
Groq LLM (Llama 3.3 70B)	   Language model for intelligent responses
dotenv	                     Load environment variables securely
Git & GitHub	               Version control and project hosting

ğŸ§© Project Structure
Langchain_chatbot/
- chatbot.py              Main chatbot logic
- requirements.txt        Dependencies
- .env                    API key (not uploaded to GitHub)
- .gitignore              Files to be ignored by Git
-  README.md              Project documentation
-  venv/                  Virtual environment (ignored)

âš™ï¸ Setup Instructions

1ï¸âƒ£ Clone the repository
git clone https://github.com/<yourusername>/Langchain_chatbot.git
cd Langchain_chatbot

2ï¸âƒ£ Create a virtual environment
python -m venv .venv
source .venv/Scripts/activate   # for Windows PowerShell

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

4ï¸âƒ£ Add your API key
Create a .env file and paste:
GROQ_API_KEY=your_api_key_here

5ï¸âƒ£ Run the chatbot
python chatbot.py

ğŸ§  What I Learned from This Project

Through this project, I gained hands-on understanding of AI pipeline fundamentals and how modern LLM frameworks operate.
Key takeaways:

ğŸ§© 1. LangChain Framework

How prompt templates dynamically control LLM behavior.

The idea of a prompt â†’ model â†’ parser chain.

Using ChatPromptTemplate to maintain structured multi-turn conversations.

âš™ï¸ 2. Large Language Models (LLMs)

Understanding how LLMs (like Llama 3.3 70B) generate context-aware responses.

How temperature affects creativity vs. accuracy in responses.

ğŸ” 3. Environment & API Management

How to use .env and dotenv to securely manage API keys.

How to use .gitignore to protect sensitive information.

ğŸ§  4. Data Engineering & AI Integration Concepts

Basics of connecting Python pipelines to LLMs using APIs.

How prompt chaining resembles data pipelines in AI/ML workflows.

Insight into building modular and reusable components for GenAI systems.

ğŸŒ 5. Git & Version Control

Initializing repositories, staging, committing, pushing.

Understanding how local and remote repos sync.

Maintaining a professional project structure on GitHub.

ğŸ’¡ Future Enhancements

Add a Streamlit UI for an interactive chat interface.

Integrate RAG (Retrieval-Augmented Generation) for domain-specific knowledge.

Store chat history using ChromaDB or FAISS for memory.

Deploy on Streamlit Cloud or AWS Lambda.


ğŸ§¬ Author
ğŸ‘©â€ğŸ’» Sanjana Ghosh
Bioinformatics & AI Enthusiast | Exploring GenAI in Healthcare
ğŸŒ LinkedIn
 â€¢ GitHub

ğŸ“œ License
This project is open-source and available under the MIT License.
